{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eab3b16-8be4-4312-a3ea-bebe00d973e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EE 5020 Homework 2: Statistical inference (frequentist)\n",
    "\n",
    "Name: FARZANA YASMIN BOBY\n",
    "\n",
    "CIN: 401413256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e776d9a-583b-4534-8e9f-b8b7c592d6ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this homework, you will practice applying your statistical inference skills on different datasets within the book. Like the previous homework's Section 2, this set of problems will be presented as datasets and associated research questions for you to answer with your own Markdown and Code cells.\n",
    "\n",
    "## Rubric for this homework\n",
    "\n",
    "Make sure you write down the reasoning and method of creation for any additional columns or transformations of data you need to create.  Additionally, make sure to justify any conclusions you make to answer questions with statistical tests.  Make sure you justify the statistical test chosen as well (for instance, unpaired vs. paired t-test).\n",
    "\n",
    "- 25% organization and flow of justification for statistical inference\n",
    "- 25% organization and flow of Python code\n",
    "- 25% correct statistical inference\n",
    "- 25% correct Python code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5cc86-6141-42fb-b5ff-3cf63e92567a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Global imports\n",
    "\n",
    "Write your imports here so you don't have to write imports below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf24eac-2f0d-4f50-b148-ee056763edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0fed40-7bc4-41b0-b009-9a6cd9d164ce",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "**Dataset:** `as_datasets/hof.csv`\n",
    "\n",
    "**Dataset description:** A data set containing number of hits and hall of fame status of various baseball players\n",
    "\n",
    "**Write and discuss the steps to answering the following research question:** Subsample the full dataset again by the last two digits of your CIN floor divided by 4. Is it more likely for a hall of famer to have more hits than a non-hall of famer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865fa934-688c-4321-bb9f-ec3e2ef79fcb",
   "metadata": {},
   "source": [
    "Subsampling the dataset df_hof by the last two digit of my CIN and renaming it to df_subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25205fc2-c062-47c1-85b7-f5572a9a7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hof = pd.read_csv(\"../as_datasets/hof.csv\")\n",
    "\n",
    "def cin_subsample_dataframe(df_input: pd.DataFrame, cin: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns subsampled dataframe based on last two digits of cin divided by 4.\n",
    "    \"\"\"\n",
    "    selection_vector = np.arange(0, len(df_input), (cin % 100) // 4)\n",
    "    return df_input.iloc[selection_vector].copy()\n",
    "\n",
    "df_subsampled = cin_subsample_dataframe(df_hof, 401413256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8537b8e-b055-43d5-839a-35d4d8a63180",
   "metadata": {},
   "source": [
    "Now, producing two new DataFrames with hall of famers and non hall of famers and renaming them df_hall_of_famer and df_non_hall_of_famer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3039a4d4-e5aa-4282-bbda-4d044f0124f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Hits  HOF\n",
      "434  1659    1\n",
      "518  1840    1\n",
      "574  2004    1\n",
      "672  2313    1\n",
      "686  2383    1\n",
      "    Hits  HOF\n",
      "0    972    0\n",
      "14  1068    0\n",
      "28  1105    0\n",
      "42  1132    0\n",
      "56  1154    0\n"
     ]
    }
   ],
   "source": [
    "df_hall_of_famer = df_subsampled[df_subsampled['HOF'] == 1]\n",
    "print(df_hall_of_famer.head())\n",
    "\n",
    "df_non_hall_of_famer = df_subsampled[df_subsampled['HOF'] == 0]\n",
    "print(df_non_hall_of_famer.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bcff4c-144e-4551-9d11-5eadef6ac1fe",
   "metadata": {},
   "source": [
    "Creating a function for getting confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354aeef0-c3c7-4a9e-9165-c7a2e156360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_interval(dataset: pd.Series, ci_level: float = 0.95, force_t: bool = False) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Returns the confidence interval for the given data series, based on the \n",
    "      z-distribution if the number of samples > 30 and the t-distribution if\n",
    "      the number of samples is less than or equal to 30.\n",
    "\n",
    "    :param dataset: a single series of data to get the confidence interval for the mean.\n",
    "    :param ci_level: level for the confidence interval\n",
    "    :param force_t: True if forced to use t distribution\n",
    "    \"\"\"\n",
    "    n = len(dataset)\n",
    "    mean = dataset.mean()\n",
    "    stdev = dataset.std()\n",
    "    stderr = stdev / np.sqrt(n)\n",
    "    if n > 30 and not force_t:\n",
    "        return scipy.stats.norm.interval(ci_level, mean, stderr)\n",
    "    else:\n",
    "        ddof = n - 1\n",
    "        return scipy.stats.t.interval(ci_level, ddof, mean, stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036de57e-d46b-4a80-bc9f-732098e72718",
   "metadata": {},
   "source": [
    "Now, getting confidence interval of number of hits for both hall of famers and non hall of famers with the help of the function and also performin individual t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8f2ac9-07a6-4801-8d77-9c1381eebd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The means for famers are: Hits    2504.444444\n",
      "HOF        1.000000\n",
      "dtype: float64\n",
      "the means for non famers are: Hits    1572.425532\n",
      "HOF        0.000000\n",
      "dtype: float64\n",
      "The 95% confidence interval of no. of hits for hall of famers is: (2012.2853905799304, 2996.6034983089585)\n",
      "The 95% confidence interval of no. of hits for non hall of famers is: (1457.4585510849813, 1687.3925127448058)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=5.85595205321475, pvalue=2.899670803354434e-07)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The means for famers are: {df_hall_of_famer.mean()}\")\n",
    "print(f\"the means for non famers are: {df_non_hall_of_famer.mean()}\")\n",
    "\n",
    "print(f\"The 95% confidence interval of no. of hits for hall of famers is: {get_confidence_interval(force_t=True, dataset=df_hall_of_famer['Hits'])}\")\n",
    "print(f\"The 95% confidence interval of no. of hits for non hall of famers is: {get_confidence_interval(force_t=True, dataset=df_non_hall_of_famer['Hits'])}\")\n",
    "scipy.stats.ttest_ind(df_hall_of_famer['Hits'], df_non_hall_of_famer['Hits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3499ebe-87a0-43e0-905b-2de93cbe73e4",
   "metadata": {},
   "source": [
    "It shows that the mean number of hits for a player who is in hall of fame is 2504.444444, and for a player of non hall of fame is 1572.425532. So, the mean hits for hall of famers is higher than non hall of famers.It's also seen that 95% of the total population of no. of hits for hall of famers lies within the range 2012.285 to 2996.603, and for non hall of famers the value lies within 1457.458 to 1687.392. After performing t-test, the result shows p value is quite smaller (<0.05). so, there is mean difference between hall of famer and non hall of famer. It's more likely for a hall of famer to have more hits than a non-hall of famer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d85e72-fa5d-4a43-a76f-b5e8ed53f9af",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "**Dataset:** `as_datasets/bac.csv`\n",
    "\n",
    "**Dataset description:** Data on blood alcohol content (BAC) and whether the subject passed or failed the standardized field sobriety test\n",
    "\n",
    "**Write and discuss the steps to answering the following research question:** How accurate is a police officer's sobriety test? In other words, do subjects who fail the sobriety test have higher BAC than subjects who passed the sobriety test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52df794-c92e-4930-9cef-967a628bf3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>BAC</th>\n",
       "      <th>PASS</th>\n",
       "      <th>forpass</th>\n",
       "      <th>pred</th>\n",
       "      <th>pass.ols</th>\n",
       "      <th>PASS.OLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518128</td>\n",
       "      <td>0.971148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464620</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797098</td>\n",
       "      <td>0.969166</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327069</td>\n",
       "      <td>0.968663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546285</td>\n",
       "      <td>0.968608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject       BAC  PASS   forpass      pred  pass.ols  PASS.OLS\n",
       "0       54  0.000344     1  0.518128  0.971148         0         0\n",
       "1       94  0.000523     1  0.464620  0.970857         0         0\n",
       "2       72  0.001530     1  0.797098  0.969166         0         1\n",
       "3        1  0.001819     1  0.327069  0.968663         0         0\n",
       "4       49  0.001850     1  0.546285  0.968608         0         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bac = pd.read_csv(\"../as_datasets/bac.csv\")\n",
    "df_bac.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af989a1-4242-473c-bf5f-3e46c090289c",
   "metadata": {},
   "source": [
    "Now, producing two new DataFrames with subjects who fails sobriety test and subjects who passes sobriety test and renaming them df_fails and df_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8488b99-b24f-4920-bc16-847eafff0cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Subject       BAC  PASS   forpass      pred  pass.ols  PASS.OLS\n",
      "9        40  0.004256     0  0.944598  0.964099         0         0\n",
      "13       41  0.010262     0  0.903742  0.949961         0         0\n",
      "17       13  0.013762     0  0.927770  0.939433         0         0\n",
      "34       20  0.036139     0  0.843834  0.809930         0         0\n",
      "38       80  0.038245     0  0.903805  0.790499         0         0\n",
      "   Subject       BAC  PASS   forpass      pred  pass.ols  PASS.OLS\n",
      "0       54  0.000344     1  0.518128  0.971148         0         0\n",
      "1       94  0.000523     1  0.464620  0.970857         0         0\n",
      "2       72  0.001530     1  0.797098  0.969166         0         1\n",
      "3        1  0.001819     1  0.327069  0.968663         0         0\n",
      "4       49  0.001850     1  0.546285  0.968608         0         0\n"
     ]
    }
   ],
   "source": [
    "df_fails = df_bac[df_bac['PASS'] == 0]\n",
    "print(df_fails.head())\n",
    "\n",
    "df_pass = df_bac[df_bac['PASS'] == 1]\n",
    "print(df_pass.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4548263-765b-477b-8fdc-e5b0c55d732c",
   "metadata": {},
   "source": [
    "Getting confidence interval using the function and performing t-test for subjects who fails sobriety test and who passes sobriety test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c57d7bc1-779c-47f9-a856-b154f66d0851",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The means for subjects who fails sobriety test are: Subject     50.076923\n",
      "BAC          0.070161\n",
      "PASS         0.000000\n",
      "forpass      0.674407\n",
      "pred         0.384627\n",
      "pass.ols     0.000000\n",
      "PASS.OLS     0.000000\n",
      "dtype: float64\n",
      "The means for subjects who passes sobriety test are: Subject     50.770492\n",
      "BAC          0.034829\n",
      "PASS         1.000000\n",
      "forpass      0.429993\n",
      "pred         0.754091\n",
      "pass.ols     0.000000\n",
      "PASS.OLS     0.245902\n",
      "dtype: float64\n",
      "The 95% confidence interval of BAC for subjects who fails sobriety test is: (0.062070381025131974, 0.07825143394922703)\n",
      "The 95% confidence interval of BAC for subjects who passess sobriety test is: (0.028862896703866825, 0.04079505936170695)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-7.194405281581035, pvalue=1.2700067956852572e-10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The means for subjects who fails sobriety test are: {df_fails.mean()}\")\n",
    "print(f\"The means for subjects who passes sobriety test are: {df_pass.mean()}\")\n",
    "\n",
    "print(f\"The 95% confidence interval of BAC for subjects who fails sobriety test is: {get_confidence_interval(force_t=True, dataset=df_fails['BAC'])}\")\n",
    "print(f\"The 95% confidence interval of BAC for subjects who passess sobriety test is: {get_confidence_interval(force_t=True, dataset=df_pass['BAC'])}\")\n",
    "scipy.stats.ttest_ind(df_pass['BAC'], df_fails['BAC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb69306-7969-4c53-b7bc-022736820cf2",
   "metadata": {},
   "source": [
    "The results show that, the mean BAC for subjects who fails the sobriety test is 0.070161 and for subjects who passes the test is 0.034829. The BAC for sobriety test failure is higher. 95% of the data for BAC lies within 0.0620... to 0.0782.. for sobriety test failure and within 0.0288... to 0.0407... for sobriety test passing. the range for BAC for sobriety test failure is higher. After performing t-test it shows a much lower pvalue (<0.05), therefore, there is a BAC difference. So, we can say that subjects who fail the sobriety test have higher BAC than subjects who passed the sobriety test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3273efc0-fdf7-489f-b1d6-b02ac407ac31",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "**Dataset:** `as_datasets/caffeine.csv`\n",
    "\n",
    "**Dataset description:** Endurance times of 9 athletes when given 5 mg and 13 mg of caffeine\n",
    "\n",
    "**Write and discuss the steps to answering the following research question:** Does a higher concentration of actually prolong the endurance time of an athlete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16de257d-a707-455b-81e8-bb48bd7332e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mg5</th>\n",
       "      <th>mg13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.05</td>\n",
       "      <td>36.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.50</td>\n",
       "      <td>46.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.25</td>\n",
       "      <td>69.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.20</td>\n",
       "      <td>70.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.47</td>\n",
       "      <td>37.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mg5   mg13\n",
       "0  35.05  36.20\n",
       "1  44.50  46.48\n",
       "2  73.25  69.47\n",
       "3  66.20  70.54\n",
       "4  42.47  37.55"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_caffeine = pd.read_csv(\"../as_datasets/caffeine.csv\")\n",
    "df_caffeine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c2a332-9905-42fd-accf-932de6d7ec3e",
   "metadata": {},
   "source": [
    "Getting confidence interval for both concentrations and applying rel t test as all the athletes are given both concentrations of caffeine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afce26a2-f8f6-42c9-ba1e-14d8e2e6410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The means are: mg5     57.676667\n",
      "mg13    58.148889\n",
      "dtype: float64\n",
      "The 95% confidence interval for mg5 is: (45.37600719147748, 69.97732614185587)\n",
      "The 95% confidence interval for mg13 is: (46.51574593835636, 69.78203183942139)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-0.12052261484527026, pvalue=0.9070411564076122)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The means are: {df_caffeine.mean()}\")\n",
    "print(f\"The 95% confidence interval for mg5 is: {get_confidence_interval(force_t=True, dataset=df_caffeine['mg5'])}\")\n",
    "print(f\"The 95% confidence interval for mg13 is: {get_confidence_interval(force_t=True, dataset=df_caffeine['mg13'])}\")\n",
    "scipy.stats.ttest_rel(df_caffeine['mg5'], df_caffeine['mg13'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43641b0-2d67-4d1d-ac24-9d10510d4c3e",
   "metadata": {},
   "source": [
    "We can see that 95% of population for concentration mg5 lies within 45.376... to 69.977... and for mg13 it's 46.515.. to 69.782... , which is close to one another. The t-test shows the statistics isn't significant and the p-value is higher than 0.05. So,  a higher concentration actually doesn't prolong the endurance time of an athlete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb4b2b-97a3-4a69-94f3-c848a3b69a2f",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "**Dataset:** `as_datasets/rent.csv`\n",
    "\n",
    "**Dataset description:** Monthly rent of 10 randomly selected apartments with less than 100 sq ft in 6 American cities\n",
    "\n",
    "**Write and discuss the steps to answering the following research question:** Which cities have similar monthly rent means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "078f298c-4033-4686-82d2-419ffc971826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Santa Monica CA</th>\n",
       "      <th>Boise ID</th>\n",
       "      <th>Tucson AZ</th>\n",
       "      <th>Detroit MI</th>\n",
       "      <th>Pittsburgh PA</th>\n",
       "      <th>Orlando FL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10230</td>\n",
       "      <td>1600</td>\n",
       "      <td>2495</td>\n",
       "      <td>3195</td>\n",
       "      <td>2480</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1500</td>\n",
       "      <td>2200</td>\n",
       "      <td>2695</td>\n",
       "      <td>2435</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000</td>\n",
       "      <td>1029</td>\n",
       "      <td>2150</td>\n",
       "      <td>2595</td>\n",
       "      <td>2405</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8500</td>\n",
       "      <td>1025</td>\n",
       "      <td>1800</td>\n",
       "      <td>2495</td>\n",
       "      <td>2350</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8250</td>\n",
       "      <td>980</td>\n",
       "      <td>1650</td>\n",
       "      <td>2495</td>\n",
       "      <td>2320</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Santa Monica CA  Boise ID  Tucson AZ  Detroit MI  Pittsburgh PA  Orlando FL\n",
       "0            10230      1600       2495        3195           2480        2242\n",
       "1            10000      1500       2200        2695           2435        2000\n",
       "2             9000      1029       2150        2595           2405        1912\n",
       "3             8500      1025       1800        2495           2350        1895\n",
       "4             8250       980       1650        2495           2320        1800"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent = pd.read_csv(\"../as_datasets/rent.csv\")\n",
    "df_rent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda78ba-ff19-42d4-a97e-75bb449f0129",
   "metadata": {},
   "source": [
    "Let's perform pairwise comparison of the mean of monthly rent of the cities by pairwise_tukey.hsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d907462-5934-4da3-ae34-0b0c7b4f70b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The means are: Santa Monica CA    7929.5\n",
      "Boise ID           1078.4\n",
      "Tucson AZ          1789.5\n",
      "Detroit MI         2096.5\n",
      "Pittsburgh PA      2344.1\n",
      "Orlando FL         1825.9\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apartment_ID</th>\n",
       "      <th>City_name</th>\n",
       "      <th>rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>Santa Monica CA</td>\n",
       "      <td>10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Santa Monica CA</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000002</td>\n",
       "      <td>Santa Monica CA</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000003</td>\n",
       "      <td>Santa Monica CA</td>\n",
       "      <td>8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000004</td>\n",
       "      <td>Santa Monica CA</td>\n",
       "      <td>8250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   apartment_ID        City_name   rent\n",
       "0       1000000  Santa Monica CA  10230\n",
       "1       1000001  Santa Monica CA  10000\n",
       "2       1000002  Santa Monica CA   9000\n",
       "3       1000003  Santa Monica CA   8500\n",
       "4       1000004  Santa Monica CA   8250"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The means are: {df_rent.mean()}\")\n",
    "# First, we need to get a \"long-form grouped\" version of df_rent:\n",
    "df_rent[\"apartment_ID\"] = df_rent.index + 1000000  # NOTE: normally dataset would have a unique identifier for each sample of data\n",
    "df_rent_long = df_rent.melt(id_vars=[\"apartment_ID\"],\n",
    "                            value_vars=[col_label for col_label in df_rent.columns],\n",
    "                            var_name=\"City_name\",\n",
    "                            value_name=\"rent\")\n",
    "df_rent_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1286e14-820f-4dee-a220-01f8151786a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multiple Comparison of Means - Tukey HSD, FWER=0.05</caption>\n",
       "<tr>\n",
       "      <th>group1</th>          <th>group2</th>      <th>meandiff</th>  <th>p-adj</th>    <th>lower</th>      <th>upper</th>   <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Boise ID</td>       <td>Detroit MI</td>     <td>1018.1</td>   <td>0.031</td>   <td>60.3579</td>   <td>1975.8421</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Boise ID</td>       <td>Orlando FL</td>      <td>747.5</td>  <td>0.2096</td>  <td>-210.2421</td>  <td>1705.2421</td>  <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Boise ID</td>      <td>Pittsburgh PA</td>   <td>1265.7</td>  <td>0.0034</td>  <td>307.9579</td>   <td>2223.4421</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Boise ID</td>     <td>Santa Monica CA</td>  <td>6851.1</td>   <td>0.001</td>  <td>5893.3579</td>  <td>7808.8421</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Boise ID</td>        <td>Tucson AZ</td>      <td>711.1</td>  <td>0.2576</td>  <td>-246.6421</td>  <td>1668.8421</td>  <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Detroit MI</td>      <td>Orlando FL</td>     <td>-270.6</td>    <td>0.9</td>  <td>-1228.3421</td>  <td>687.1421</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Detroit MI</td>     <td>Pittsburgh PA</td>    <td>247.6</td>    <td>0.9</td>   <td>-710.1421</td>  <td>1205.3421</td>  <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Detroit MI</td>    <td>Santa Monica CA</td>  <td>5833.0</td>   <td>0.001</td>  <td>4875.2579</td>  <td>6790.7421</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Detroit MI</td>       <td>Tucson AZ</td>     <td>-307.0</td>    <td>0.9</td>  <td>-1264.7421</td>  <td>650.7421</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Orlando FL</td>     <td>Pittsburgh PA</td>    <td>518.2</td>   <td>0.59</td>   <td>-439.5421</td>  <td>1475.9421</td>  <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Orlando FL</td>    <td>Santa Monica CA</td>  <td>6103.6</td>   <td>0.001</td>  <td>5145.8579</td>  <td>7061.3421</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Orlando FL</td>       <td>Tucson AZ</td>      <td>-36.4</td>    <td>0.9</td>   <td>-994.1421</td>  <td>921.3421</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>Pittsburgh PA</td>  <td>Santa Monica CA</td>  <td>5585.4</td>   <td>0.001</td>  <td>4627.6579</td>  <td>6543.1421</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>Pittsburgh PA</td>     <td>Tucson AZ</td>     <td>-554.6</td>  <td>0.5268</td> <td>-1512.3421</td>  <td>403.1421</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Santa Monica CA</td>    <td>Tucson AZ</td>     <td>-6140.0</td>  <td>0.001</td> <td>-7097.7421</td> <td>-5182.2579</td>  <td>True</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "rent_hsd = pairwise_tukeyhsd(endog=df_rent_long['rent'], groups=df_rent_long[\"City_name\"])\n",
    "\n",
    "rent_hsd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ebaa6-c13d-4e65-b80e-5d4456aa99eb",
   "metadata": {},
   "source": [
    "From the above result it's seen that, Boise ID\tOrlando FL, Boise ID\tTucson AZ, Detroit MI\tOrlando FL, Detroit MI\tPittsburgh PA, Detroit MI\tTucson AZ, Orlando FL\tPittsburgh PA, Orlando FL\tTucson AZ, Pittsburgh PA\tTucson AZ, these pair of cities have almost similar monthly rent means. There exists small mean difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daca46c3-d6d9-4072-8c36-595ed9a6175a",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "**Dataset:** `as_datasets/gpa.csv`\n",
    "\n",
    "**Dataset description:** A toy data set containing the heights and gpa of 35 students\n",
    "\n",
    "**Write and discuss the steps to answering the following research question:** Is there a GPA difference between with students in each quartile (25%) of height?  In other words, do students who are in the bottom 25% of height have a different GPA than students who are in the 25-50% or 50-75% or 75-100% of height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323027e9-bd7e-423e-b969-b0b48b447923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.814286</td>\n",
       "      <td>2.971714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.340449</td>\n",
       "      <td>0.535040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.500000</td>\n",
       "      <td>2.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>3.860000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          height        gpa\n",
       "count  35.000000  35.000000\n",
       "mean   66.814286   2.971714\n",
       "std     4.340449   0.535040\n",
       "min    57.000000   1.500000\n",
       "25%    63.500000   2.725000\n",
       "50%    67.000000   3.000000\n",
       "75%    70.000000   3.330000\n",
       "max    74.000000   3.860000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpa = pd.read_csv(\"../as_datasets/gpa.csv\")\n",
    "df_gpa.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e3c1d-96bf-4c16-90a0-3d4ab642062c",
   "metadata": {},
   "source": [
    "Getting the quartiles of height and then creating new DataFrames with 0-25%, 25-50%, 50-75%, 75-100% of heights and their corresponding gpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65d6e0b7-4dae-4ed8-a330-3fd4691808f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_quartile = np.quantile(df_gpa['height'], .25)\n",
    "second_quartile = np.quantile(df_gpa['height'], .5)\n",
    "third_quartile = np.quantile(df_gpa['height'], .75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8b15a09-4472-480e-9fa0-1d34474d44fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_quart:\n",
      "   height   gpa\n",
      "0    66.0  2.90\n",
      "2    64.5  3.62\n",
      "4    69.5  3.45\n",
      "5    65.0  2.80\n",
      "7    68.0  2.81\n",
      "second_quart:\n",
      "    height   gpa\n",
      "0     66.0  2.90\n",
      "2     64.5  3.62\n",
      "5     65.0  2.80\n",
      "9     64.0  2.75\n",
      "12    66.0  2.49\n",
      "third_quart:\n",
      "    height   gpa\n",
      "4     69.5  3.45\n",
      "7     68.0  2.81\n",
      "10    69.0  3.86\n",
      "11    70.0  1.50\n",
      "14    69.0  2.70\n",
      "last_quart:\n",
      "    height   gpa\n",
      "13    73.0  3.10\n",
      "17    72.0  2.84\n",
      "18    72.0  2.85\n",
      "19    73.5  3.33\n",
      "28    71.5  3.20\n"
     ]
    }
   ],
   "source": [
    "df_first_quart = df_gpa[df_gpa['height'] > first_quartile]\n",
    "print(f\"first_quart:\\n{df_first_quart.head()}\")\n",
    "\n",
    "df_second_quart = df_gpa[(first_quartile < df_gpa['height']) & (df_gpa['height'] <= second_quartile)]\n",
    "print(f\"second_quart:\\n{df_second_quart.head()}\")\n",
    "\n",
    "df_third_quart = df_gpa[(second_quartile < df_gpa['height']) & (df_gpa['height'] <= third_quartile)]\n",
    "print(f\"third_quart:\\n{df_third_quart.head()}\")\n",
    "\n",
    "df_last_quart = df_gpa[df_gpa['height'] > third_quartile]\n",
    "print(f\"last_quart:\\n{df_last_quart.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c0160f-e6a3-49a3-9d9a-bb53e89c0bc8",
   "metadata": {},
   "source": [
    "Now, getting confidence interval for the gpa of each quartiles and performing oneway ANOVA test to see if they have similar or different means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24e6a875-8481-43c8-a799-42a67b46b718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The means are: (height    68.769231\n",
      "gpa        2.979231\n",
      "dtype: float64, height    65.750\n",
      "gpa        3.111\n",
      "dtype: float64, height    68.9375\n",
      "gpa        2.8050\n",
      "dtype: float64, height    72.37500\n",
      "gpa        2.98875\n",
      "dtype: float64)\n",
      "The 95% confidence interval for 1st quartile is: (2.770526239170903, 3.1879352992906362)\n",
      "The 95% confidence interval for 2nd quartile is: (2.8031757178342227, 3.418824282165777)\n",
      "The 95% confidence interval for 3rd quartile is: (2.166504536803136, 3.4434954631968635)\n",
      "The 95% confidence interval for last quartile is: (2.763514220414494, 3.213985779585506)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.5161712753320405, pvalue=0.6731251730511894)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The means are: {df_first_quart.mean(), df_second_quart.mean(), df_third_quart.mean(), df_last_quart.mean()}\")\n",
    "\n",
    "print(f\"The 95% confidence interval for 1st quartile is: {get_confidence_interval(force_t=True, dataset=df_first_quart['gpa'])}\")\n",
    "print(f\"The 95% confidence interval for 2nd quartile is: {get_confidence_interval(force_t=True, dataset=df_second_quart['gpa'])}\")\n",
    "print(f\"The 95% confidence interval for 3rd quartile is: {get_confidence_interval(force_t=True, dataset=df_third_quart['gpa'])}\")\n",
    "print(f\"The 95% confidence interval for last quartile is: {get_confidence_interval(force_t=True, dataset=df_last_quart['gpa'])}\")\n",
    "\n",
    "scipy.stats.f_oneway(df_first_quart['gpa'], df_second_quart['gpa'], df_third_quart['gpa'], df_last_quart['gpa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0ee31-7c95-462e-af5e-5e54bad255d3",
   "metadata": {},
   "source": [
    "It's clear from the test result that the statistics is not significant. The p value is higher (>0.05). So, there is no significant GPA difference between with students in each quartile (25%) of height. Students who are in the bottom 25% of height don't have different GPA than students who are in the 25-50% or 50-75% or 75-100% of height. In other words, GPA doesn't depend on the heights of students."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
