import statsmodels.api
import statsmodels.formula.api
import numpy as np
import pandas as pd
import scipy.stats
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn.datasets
import sklearn.svm
import sklearn.linear_model
import sklearn.model_selection





def calc_mse(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """
    Returns the mean squared error given y_true and y_pred.
    """
    return np.sum(np.square(y_true-y_pred)) * 1/(y_true.size)


df_diabetes = pd.read_csv('https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt',
                          sep='\t')
df_diabetes.columns = df_diabetes.columns.str.lower()
df_diabetes.head()
df_diabetes_data = df_diabetes.drop('y', axis=1)
df_diabetes_target = df_diabetes['y'].copy()
print(f"Data:\n{df_diabetes_data.head()}")
print(f"Target:\n{df_diabetes_target.head()}")


sns.pairplot(data=df_diabetes, hue='y', kind='scatter', palette='plasma')


df_diabetes_data_subbed = df_diabetes_data[['bmi', 'bp', 's4', 's5', 's6']]

regress_diabetes_model = sklearn.linear_model.LinearRegression()
regress_diabetes_model.fit(df_diabetes_data_subbed, df_diabetes_target)
print(f"fit score: {regress_diabetes_model.score(df_diabetes_data_subbed, df_diabetes_target)}")
print(f"coef names: {regress_diabetes_model.feature_names_in_}")
print(f"coefficients: {regress_diabetes_model.coef_}")
print(f"intercept: {regress_diabetes_model.intercept_}")


def test_linear_regressor(model_to_use: object,
                          true_features: pd.DataFrame,
                          true_targets: pd.Series) -> object:
    """
    Test a linear regressor (assuming models in sklearn.linear_model).
    
    :param model_to_use: The model to use (e.g. sklearn.linear_model.Ridge)
    :param true_feature: The dataframe of features from the dataset
    :param true_targets: The series of targets from the dataset
    :returns: the trained model
    """
    model = model_to_use()
    model.fit(true_features, true_targets)
    print(f"Testing model: {model}")
    print(f"fit score: {model.score(true_features, true_targets)}")
    print(f"coef names: {model.feature_names_in_}")
    print(f"coefficients: {model.coef_}")
    print(f"intercept: {model.intercept_}")
    return model

test_linear_regressor(sklearn.linear_model.Ridge, df_diabetes_data_subbed, df_diabetes_target)
test_linear_regressor(sklearn.linear_model.ElasticNet, df_diabetes_data_subbed, df_diabetes_target)


svm_diabetes_model = sklearn.svm.SVR(kernel="linear")
svm_diabetes_model.fit(df_diabetes_data_subbed, df_diabetes_target)
print(f"fit score: {svm_diabetes_model.score(df_diabetes_data_subbed, df_diabetes_target)}")
print(f"coef names: {svm_diabetes_model.feature_names_in_}")
print(f"coefficients: {svm_diabetes_model.coef_}")
print(f"intercept: {svm_diabetes_model.intercept_}")
print(f"support vectors: {svm_diabetes_model.support_vectors_}")


svm_diabetes_model = sklearn.svm.SVR(kernel="linear")
scores = sklearn.model_selection.cross_val_score(svm_diabetes_model, 
                                                 df_diabetes_data_subbed, 
                                                 df_diabetes_target, 
                                                 cv=7)
print(f"Cross-validation scores: {scores}")


import sklearn.ensemble

rf_diabetes_model = sklearn.ensemble.RandomForestRegressor(n_estimators=1000)
scores = sklearn.model_selection.cross_val_score(rf_diabetes_model, 
                                                 df_diabetes_data, 
                                                 df_diabetes_target, 
                                                 cv=7,
                                                 verbose=2)
print(f"Cross-validation scores: {scores}")


from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression

feature_selector = SelectKBest(f_regression, k=6)
feature_selector.fit_transform(df_diabetes_data, df_diabetes_target)
features_info = zip(feature_selector.feature_names_in_, feature_selector.pvalues_, feature_selector.scores_)
print("f_regression (linear assumption) results:")
for feature_name, p_value, score in features_info:  # TODO: sort
    print(f"{feature_name}: {score} with p-value {p_value}")


feature_selector = SelectKBest(mutual_info_regression, k=6)
feature_selector.fit_transform(df_diabetes_data, df_diabetes_target)
features_info = zip(feature_selector.feature_names_in_, feature_selector.scores_)
print("mutual_info_regression (nonlinear assumption) results:")
for feature_name, score in features_info:
    print(f"{feature_name}: {score}")


import numpy as np
import pandas as pd
import seaborn as sns
import scipy.stats

grades = np.array(sorted([5.5, 10, 10, 5.5, 5, 7.75, 4.5, 5.5, 5.5, 10, 9.5, 5.5, 8.25, 10, 9.9, 6.5, 9]))
df_grades = pd.Series(grades)
df_grades.describe()
print(f"mode 1: {df_grades[df_grades < 7.75].mean()}")
print(f"mode 2: {df_grades[df_grades >= 7.75].mean()}")
scipy.stats.ttest_ind(df_grades[df_grades < 7.75], df_grades[df_grades >= 7.75])



sns.histplot(df_grades, binrange=(0.0, 10.0))


import numpy as np
import pandas as pd
import seaborn as sns

import sklearn.pipeline
import sklearn.svm



































import joblib
import sklearn.pipeline
import sklearn.preprocessing
import sklearn.linear_model
import sklearn.model_selection

num_cores = 4












